{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO:\n",
    "\n",
    "- Build pure ViT with new TP architecture\n",
    "    - Use lucidrains base, 2 layers\n",
    "    - Create my TP-Block\n",
    "- Extend to language\n",
    "- Explore use of T2T for vision pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class RandomImageDataset(Dataset):\n",
    "    def __init__(self, n_samples):\n",
    "        assert n_samples % 2 == 0, \"n_samples must be an even number\"\n",
    "        self.n_samples = n_samples\n",
    "        self.labels = [0] * int(self.n_samples/2) + [1] * int(self.n_samples/2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx < self.n_samples/2:\n",
    "            x = torch.normal(0, 0.1, size=(3, 224, 224))\n",
    "        else:\n",
    "            x = torch.normal(1, 0.1, size=(3, 224, 224))\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "    \n",
    "train_ds = RandomImageDataset(100)\n",
    "train_datagen = DataLoader(train_ds, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tpr_block_vit import TP_ViT\n",
    "\n",
    "model = TP_ViT(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_classes=2,\n",
    "    dim=768,\n",
    "    depth=2,\n",
    "    heads=8,\n",
    "    mlp_dim=3072\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE TO SELF:\n",
    "\n",
    "Query size should be size of dim head - aka not 768 but 768/n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 0.001\n",
      "[1,    10] loss: 0.000\n",
      "[1,    15] loss: 0.000\n",
      "[1,    20] loss: 0.000\n",
      "[1,    25] loss: 0.000\n",
      "[1,    30] loss: 0.000\n",
      "[1,    35] loss: 0.000\n",
      "[1,    40] loss: 0.000\n",
      "[1,    45] loss: 0.000\n",
      "[1,    50] loss: 0.000\n",
      "[2,     5] loss: 0.000\n",
      "[2,    10] loss: 0.000\n",
      "[2,    15] loss: 0.000\n",
      "[2,    20] loss: 0.000\n",
      "[2,    25] loss: 0.000\n",
      "[2,    30] loss: 0.000\n",
      "[2,    35] loss: 0.000\n",
      "[2,    40] loss: 0.000\n",
      "[2,    45] loss: 0.000\n",
      "[2,    50] loss: 0.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_datagen, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 768, 197, 8])\n"
     ]
    }
   ],
   "source": [
    "'''Below is the correct matmul implementation\n",
    "for TPR with elementwise multiplication across the \n",
    "embedding dimension'''\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "f = torch.rand((7, 768, 197, 1)) # b, d, n, 1\n",
    "r = torch.rand((7, 768, 1, 8)) # b, d, 1, r\n",
    "\n",
    "out = torch.matmul(f, r)\n",
    "\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5913],\n",
      "          [0.5172],\n",
      "          [0.1101]],\n",
      "\n",
      "         [[0.9911],\n",
      "          [0.5339],\n",
      "          [0.3225]]]])\n",
      "tensor([[[[0.5453, 0.7955, 0.5617, 0.5944]],\n",
      "\n",
      "         [[0.9313, 0.0784, 0.9523, 0.9734]]]])\n",
      "tensor([[[[0.3224, 0.4704, 0.3321, 0.3515],\n",
      "          [0.2820, 0.4114, 0.2905, 0.3074],\n",
      "          [0.0600, 0.0876, 0.0618, 0.0654]],\n",
      "\n",
      "         [[0.9229, 0.0777, 0.9437, 0.9647],\n",
      "          [0.4972, 0.0419, 0.5084, 0.5197],\n",
      "          [0.3004, 0.0253, 0.3071, 0.3139]]]])\n"
     ]
    }
   ],
   "source": [
    "f = torch.rand((1, 2, 3, 1))\n",
    "r = torch.rand((1, 2, 1, 4))\n",
    "\n",
    "out = torch.matmul(f, r)\n",
    "\n",
    "print(f)\n",
    "print(r)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "role-1 token-1 = 0.3224, 0.9229\n",
    "\n",
    "Should be from 0.5453 * 0.5913, 0.9313 * 0.9911\n",
    "\n",
    "role-3 token-2 = 0.2905, 0.5084\n",
    "\n",
    "Should be from 0.5617 * 0.5172, 0.9523 * 0.5339"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Parameter containing:\n",
      "tensor([[-0.2226, -0.0301, -0.2079,  0.2085, -0.0009, -0.0717,  0.1685, -0.2243,\n",
      "          0.0261, -0.1489, -0.1216, -0.0095],\n",
      "        [ 0.0681,  0.1024, -0.2068, -0.1476,  0.0485,  0.0148, -0.1064,  0.0873,\n",
      "          0.0888, -0.0157,  0.0807,  0.0339]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1804, 0.0633], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "net = TP_ViT(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_classes=2,\n",
    "    dim=768,\n",
    "    depth=2,\n",
    "    heads=12,\n",
    "    mlp_dim=3072,\n",
    "    n_roles=12\n",
    ")\n",
    "x = torch.ones((1, 3, 224, 224))\n",
    "# compute the forward pass to create the computation graph\n",
    "y = net(x)\n",
    "\n",
    "# use computation graph to find all contributing tensors\n",
    "def get_contributing_params(y, top_level=True):\n",
    "    nf = y.grad_fn.next_functions if top_level else y.next_functions\n",
    "    for f, _ in nf:\n",
    "        try:\n",
    "            yield f.variable\n",
    "        except AttributeError:\n",
    "            pass  # node has no tensor\n",
    "        if f is not None:\n",
    "            yield from get_contributing_params(f, top_level=False)\n",
    "\n",
    "contributing_parameters = set(get_contributing_params(y))\n",
    "all_parameters = set(net.parameters())\n",
    "non_contributing = all_parameters - contributing_parameters\n",
    "print(non_contributing)  # returns the [999999.0] tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
